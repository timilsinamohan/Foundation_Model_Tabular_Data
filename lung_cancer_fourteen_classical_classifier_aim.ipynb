{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f28446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c82bc440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, average_precision_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.semi_supervised import LabelSpreading, LabelPropagation\n",
    "\n",
    "# Set a global random seed\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46afb594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pre_processing(df):\n",
    "    timestamp_columns = [col for col in df.columns if \"timestamp\" in col]\n",
    "    other_non_imp_column_to_remove = [\"id\",\"general_relapse_class\"]\n",
    "    columns_with_all_nan = df.columns[df.isna().all(axis=0)].tolist()\n",
    "    print(\"shape of the datafram before dropping columns\",df.shape)\n",
    "    df.drop(timestamp_columns + other_non_imp_column_to_remove + columns_with_all_nan, axis=1, inplace=True)\n",
    "    print(\"shape of the datafram after dropping columns\",df.shape)\n",
    "    # # Validate column lists\n",
    "    categorical = df.select_dtypes(include=['bool', 'object']).columns.tolist()\n",
    "    numerical = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    # columns_with_all_nan = df.columns[df.isna().all(axis=0)]\n",
    "    # print(\"Columns with all NaN\",columns_with_all_nan)\n",
    "\n",
    "    print(\"Length of categorical and numerical columns:\", len(categorical),len(numerical))\n",
    "    # Apply KNN imputation\n",
    "    imputer = KNNImputer(n_neighbors=5, weights='uniform')\n",
    "    imputed_data = imputer.fit_transform(df[numerical])\n",
    "    print(imputed_data.shape)\n",
    "    df_imputed_numerical = pd.DataFrame(imputed_data, columns=numerical, index=df.index)\n",
    "    df[numerical] = df_imputed_numerical\n",
    "    return pd.get_dummies(df, columns=categorical, drop_first=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d7b7238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the datafram before dropping columns (1348, 76)\n",
      "shape of the datafram after dropping columns (1348, 70)\n",
      "Length of categorical and numerical columns: 59 11\n",
      "(1348, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>chemotherapy@t1_start_time</th>\n",
       "      <th>radiotherapy@t1_duration_days</th>\n",
       "      <th>surgery@t1_time</th>\n",
       "      <th>nb_cig_packs_year</th>\n",
       "      <th>nb_cigs_day</th>\n",
       "      <th>family_lung_cancer</th>\n",
       "      <th>family_other_cancer</th>\n",
       "      <th>diagnosis_ecog</th>\n",
       "      <th>radiotherapy@t1_dose</th>\n",
       "      <th>...</th>\n",
       "      <th>adeno_histology_Micropapillary</th>\n",
       "      <th>adeno_histology_Mucinous</th>\n",
       "      <th>adeno_histology_Others</th>\n",
       "      <th>adeno_histology_Papillary</th>\n",
       "      <th>adeno_histology_Solid</th>\n",
       "      <th>adeno_histology_Unknown</th>\n",
       "      <th>biomarker@diagnosis_type_EGFR</th>\n",
       "      <th>biomarker@diagnosis_type_KRAS</th>\n",
       "      <th>biomarker@diagnosis_type_PDL1</th>\n",
       "      <th>biomarker@diagnosis_type_ROS1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>43.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.6</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>34.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>21.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  chemotherapy@t1_start_time  radiotherapy@t1_duration_days  \\\n",
       "0  68.0                         3.0                           43.2   \n",
       "1  63.0                        64.0                           34.8   \n",
       "2  66.0                        28.0                           34.6   \n",
       "3  81.0                         4.8                           21.2   \n",
       "4  63.0                         3.0                           38.2   \n",
       "\n",
       "   surgery@t1_time  nb_cig_packs_year  nb_cigs_day  family_lung_cancer  \\\n",
       "0              2.0               44.6         24.0                 0.0   \n",
       "1              1.0               86.0         40.0                 0.0   \n",
       "2              2.0               60.0         40.0                 0.0   \n",
       "3              2.2               80.0         30.0                 0.0   \n",
       "4              1.0               30.0         20.0                 1.0   \n",
       "\n",
       "   family_other_cancer  diagnosis_ecog  radiotherapy@t1_dose  ...  \\\n",
       "0                  1.0             1.0                  58.2  ...   \n",
       "1                  0.0             2.0                  52.6  ...   \n",
       "2                  0.0             0.0                  50.8  ...   \n",
       "3                  0.0             1.0                  41.4  ...   \n",
       "4                  1.0             0.0                  52.2  ...   \n",
       "\n",
       "   adeno_histology_Micropapillary  adeno_histology_Mucinous  \\\n",
       "0                               0                         0   \n",
       "1                               0                         0   \n",
       "2                               0                         0   \n",
       "3                               0                         0   \n",
       "4                               0                         0   \n",
       "\n",
       "   adeno_histology_Others  adeno_histology_Papillary  adeno_histology_Solid  \\\n",
       "0                       0                          0                      0   \n",
       "1                       0                          0                      0   \n",
       "2                       0                          0                      0   \n",
       "3                       0                          0                      0   \n",
       "4                       0                          0                      0   \n",
       "\n",
       "   adeno_histology_Unknown  biomarker@diagnosis_type_EGFR  \\\n",
       "0                        0                              0   \n",
       "1                        1                              0   \n",
       "2                        0                              0   \n",
       "3                        0                              0   \n",
       "4                        0                              0   \n",
       "\n",
       "   biomarker@diagnosis_type_KRAS  biomarker@diagnosis_type_PDL1  \\\n",
       "0                              0                              0   \n",
       "1                              0                              0   \n",
       "2                              0                              0   \n",
       "3                              0                              0   \n",
       "4                              0                              0   \n",
       "\n",
       "   biomarker@diagnosis_type_ROS1  \n",
       "0                              0  \n",
       "1                              0  \n",
       "2                              0  \n",
       "3                              0  \n",
       "4                              0  \n",
       "\n",
       "[5 rows x 152 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv(\"/home/mohan/Hospital_TCGA/Data/patient_features.csv\")\n",
    "df = pd.read_csv(\"/home/mohan/Hospital_TCGA/Data/patient_features_early_stage.csv\")\n",
    "# df.head()\n",
    "# print(sorted(df.columns.values))\n",
    "df.rename(columns={'relapse?': 'general_relapse_class'}, inplace=True)\n",
    "y = df[\"general_relapse_class\"].values\n",
    "df_encoded = data_pre_processing(df)\n",
    "# df_encoded.to_csv(\"sample.csv\", sep = \",\")\n",
    "X = df_encoded.values\n",
    "X.shape\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d6e4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grids\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"C\": [0.01, 0.1, 1],\n",
    "        \"penalty\": [\"l1\", \"l2\"]\n",
    "    },\n",
    "    \"Ridge Classifier\": {\n",
    "        \"alpha\": [0.1, 1, 10, 100]\n",
    "    },\n",
    "    \"LDA\": {\n",
    "#         \"solver\": [\"svd\", \"lsqr\", \"eigen\"]\n",
    "    },\n",
    "    \"QDA\": {\n",
    "        \"reg_param\": [0.0, 0.1, 0.2, 0.3]\n",
    "    },\n",
    "    \"SVC\": {\n",
    "#         \"C\": [0.1, 1, 10],\n",
    "#         \"kernel\": [\"linear\"],\n",
    "#         \"degree\": [2, 3, 4]  # Only used if kernel is 'poly'\n",
    "    },\n",
    "    \"KNeighbors\": {\n",
    "        \"n_neighbors\": [3, 5, 7, 9],\n",
    "        \"metric\": [\"euclidean\"]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [10, 20, 30]\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"learning_rate\": [0.01, 0.1],\n",
    "        \n",
    "    },\n",
    "    \"Gaussian NB\": {},\n",
    "    \"Decision Tree\": {\n",
    "        \"max_depth\": [5, 10, 20],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "    },\n",
    "    \"MLP Classifier\": {\n",
    "        \"hidden_layer_sizes\": [(50,), (100,), (50, 50)],\n",
    "        \"activation\": [\"relu\"]\n",
    "    },\n",
    "    \"Label Spreading\": {\n",
    "        \"alpha\": [0.01, 0.1, 0.2, 0.5]\n",
    "    },\n",
    "    \"Label Propagation\": {\n",
    "        \n",
    "    },\n",
    "    \"AdaBoost\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"learning_rate\": [0.01, 0.1, 1]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c497d494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "6 fits failed out of a total of 12.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.66405419        nan 0.71878499        nan 0.71922595]\n",
      "  warnings.warn(\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "6 fits failed out of a total of 12.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.66751336        nan 0.71785907        nan 0.71584415]\n",
      "  warnings.warn(\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "6 fits failed out of a total of 12.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.65752174        nan 0.70914115        nan 0.70765948]\n",
      "  warnings.warn(\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "6 fits failed out of a total of 12.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.66239427        nan 0.71647587        nan 0.72210453]\n",
      "  warnings.warn(\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "6 fits failed out of a total of 12.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.68271961        nan 0.73259318        nan 0.72694911]\n",
      "  warnings.warn(\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "6 fits failed out of a total of 12.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.67436389        nan 0.72885047        nan 0.72633214]\n",
      "  warnings.warn(\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "6 fits failed out of a total of 12.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.66947023        nan 0.72591621        nan 0.72115751]\n",
      "  warnings.warn(\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "6 fits failed out of a total of 12.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.65210784        nan 0.70776519        nan 0.71315267]\n",
      "  warnings.warn(\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "6 fits failed out of a total of 12.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.68029799        nan 0.73597988        nan 0.73245141]\n",
      "  warnings.warn(\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "6 fits failed out of a total of 12.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.65562211        nan 0.70471596        nan 0.70538415]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Ridge Classifier\n",
      "Evaluating LDA\n",
      "Evaluating QDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mohan/anaconda3/envs/textemb/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SVC\n",
      "Evaluating KNeighbors\n",
      "Evaluating Random Forest\n",
      "Evaluating Gradient Boosting\n",
      "Evaluating Gaussian NB\n",
      "Evaluating Decision Tree\n",
      "Evaluating MLP Classifier\n",
      "Evaluating Label Spreading\n",
      "Evaluating Label Propagation\n",
      "Evaluating AdaBoost\n"
     ]
    }
   ],
   "source": [
    "# Define the classifiers\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=10000,n_jobs=-1, random_state= random_state),\n",
    "    \"Ridge Classifier\": RidgeClassifier(),\n",
    "    \"LDA\": LinearDiscriminantAnalysis(),\n",
    "    \"QDA\": QuadraticDiscriminantAnalysis(),\n",
    "    \"SVC\": SVC(probability=True,random_state=random_state),\n",
    "    \"KNeighbors\": KNeighborsClassifier(n_jobs=-1),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=random_state,n_jobs=-1),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=random_state),\n",
    "    \"Gaussian NB\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=random_state),\n",
    "    \"MLP Classifier\": MLPClassifier(max_iter=1000,random_state=random_state),\n",
    "    \"Label Spreading\": LabelSpreading(kernel='knn', max_iter=1000,n_jobs=-1),  # Specify kernel for LabelSpreading\n",
    "    \"Label Propagation\": LabelPropagation(kernel='knn', max_iter=1000,n_jobs=-1),  # Specify kernel for LabelPropagation\n",
    "    \"AdaBoost\": AdaBoostClassifier(algorithm=\"SAMME\", random_state=random_state)\n",
    "   \n",
    "}\n",
    "\n",
    "# Initialize 5-Fold Stratified CV\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "# cv = KFold(n_splits=10,random_state=42,shuffle=True)\n",
    "# Initialize dict to store scores\n",
    "scores = {name: {\"AUC-PR\": [], \"AUC-ROC\": [], \"Precision\": [], \"Recall\": [], \"F1-score\": [],\"Accuracy\": []} for name in classifiers}\n",
    "\n",
    "# Perform 5-Fold CV and calculate metrics\n",
    "for name, classifier in classifiers.items():\n",
    "    print(f\"Evaluating {name}\")\n",
    "    for train_idx, test_idx in cv.split(X, y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        grid_search = GridSearchCV(classifier, param_grids[name], cv=2, scoring='roc_auc')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred =  best_model.predict(X_test)\n",
    "#         classifier.fit(X_train, y_train)\n",
    "#         y_pred = classifier.predict(X_test)\n",
    "\n",
    "        # Check if classifier supports `predict_proba`\n",
    "        if hasattr(classifier, \"predict_proba\"):\n",
    "            y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "            scores[name][\"AUC-PR\"].append(average_precision_score(y_test, y_pred_proba))\n",
    "            scores[name][\"AUC-ROC\"].append(roc_auc_score(y_test, y_pred_proba))\n",
    "        else:\n",
    "            # If no `predict_proba`, mark AUC scores as not applicable\n",
    "            scores[name][\"AUC-PR\"].append(np.nan)\n",
    "            scores[name][\"AUC-ROC\"].append(np.nan)\n",
    "\n",
    "        # Calculate Precision, Recall, and F1-score\n",
    "        scores[name][\"Precision\"].append(precision_score(y_test, y_pred, zero_division=0))\n",
    "        scores[name][\"Recall\"].append(recall_score(y_test, y_pred, zero_division=0))\n",
    "        scores[name][\"F1-score\"].append(f1_score(y_test, y_pred, zero_division=0))\n",
    "        scores[name][\"Accuracy\"].append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Convert scores to a pandas DataFrame for nicer display, formatting mean Â± std dev\n",
    "# Assuming `scores` dictionary is already populated\n",
    "# Initialize a list to store raw scores for sorting\n",
    "raw_results = []\n",
    "\n",
    "for name in scores:\n",
    "    for metric, values in scores[name].items():\n",
    "        if metric == \"AUC-PR\":\n",
    "            metric_scores = [score for score in values if not np.isnan(score)]\n",
    "            if metric_scores:\n",
    "                avg_score = np.mean(metric_scores)\n",
    "                # Store raw mean scores for AUC-PR for sorting\n",
    "                raw_results.append((name, avg_score))\n",
    "\n",
    "# Sort classifiers based on mean AUC-PR score in descending order\n",
    "sorted_classifiers = sorted(raw_results, key=lambda x: x[1], reverse=False)\n",
    "\n",
    "# Now, format and display results in sorted order\n",
    "results = []\n",
    "\n",
    "for name, _ in sorted_classifiers:\n",
    "    result_entry = {\"Classifier\": name}\n",
    "    for metric in scores[name]:\n",
    "        metric_scores = [score for score in scores[name][metric] if not np.isnan(score)]\n",
    "        if metric_scores:\n",
    "            avg_score = np.mean(metric_scores)\n",
    "            std_dev = np.std(metric_scores)\n",
    "            result_entry[metric] = f\"{avg_score:.3f} Â± {std_dev:.3f}\"\n",
    "        else:\n",
    "            result_entry[metric] = \"N/A\"\n",
    "    results.append(result_entry)\n",
    "\n",
    "# Create DataFrame from sorted and formatted results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.set_index(\"Classifier\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bcb0555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC-PR</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Label Propagation</th>\n",
       "      <td>0.458 Â± 0.048</td>\n",
       "      <td>0.579 Â± 0.048</td>\n",
       "      <td>0.492 Â± 0.090</td>\n",
       "      <td>0.271 Â± 0.071</td>\n",
       "      <td>0.348 Â± 0.081</td>\n",
       "      <td>0.634 Â± 0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighbors</th>\n",
       "      <td>0.458 Â± 0.046</td>\n",
       "      <td>0.578 Â± 0.051</td>\n",
       "      <td>0.502 Â± 0.078</td>\n",
       "      <td>0.255 Â± 0.063</td>\n",
       "      <td>0.336 Â± 0.070</td>\n",
       "      <td>0.638 Â± 0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label Spreading</th>\n",
       "      <td>0.478 Â± 0.056</td>\n",
       "      <td>0.581 Â± 0.046</td>\n",
       "      <td>0.516 Â± 0.109</td>\n",
       "      <td>0.249 Â± 0.068</td>\n",
       "      <td>0.332 Â± 0.077</td>\n",
       "      <td>0.640 Â± 0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.497 Â± 0.070</td>\n",
       "      <td>0.607 Â± 0.051</td>\n",
       "      <td>0.000 Â± 0.000</td>\n",
       "      <td>0.000 Â± 0.000</td>\n",
       "      <td>0.000 Â± 0.000</td>\n",
       "      <td>0.636 Â± 0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian NB</th>\n",
       "      <td>0.514 Â± 0.052</td>\n",
       "      <td>0.668 Â± 0.038</td>\n",
       "      <td>0.507 Â± 0.043</td>\n",
       "      <td>0.635 Â± 0.102</td>\n",
       "      <td>0.559 Â± 0.048</td>\n",
       "      <td>0.638 Â± 0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.635 Â± 0.075</td>\n",
       "      <td>0.719 Â± 0.058</td>\n",
       "      <td>0.790 Â± 0.088</td>\n",
       "      <td>0.387 Â± 0.107</td>\n",
       "      <td>0.507 Â± 0.109</td>\n",
       "      <td>0.736 Â± 0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Classifier</th>\n",
       "      <td>0.640 Â± 0.088</td>\n",
       "      <td>0.739 Â± 0.065</td>\n",
       "      <td>0.619 Â± 0.114</td>\n",
       "      <td>0.495 Â± 0.173</td>\n",
       "      <td>0.522 Â± 0.117</td>\n",
       "      <td>0.691 Â± 0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.666 Â± 0.075</td>\n",
       "      <td>0.758 Â± 0.063</td>\n",
       "      <td>0.725 Â± 0.070</td>\n",
       "      <td>0.399 Â± 0.063</td>\n",
       "      <td>0.512 Â± 0.058</td>\n",
       "      <td>0.725 Â± 0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.690 Â± 0.057</td>\n",
       "      <td>0.770 Â± 0.040</td>\n",
       "      <td>0.648 Â± 0.065</td>\n",
       "      <td>0.521 Â± 0.083</td>\n",
       "      <td>0.576 Â± 0.073</td>\n",
       "      <td>0.723 Â± 0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.693 Â± 0.060</td>\n",
       "      <td>0.769 Â± 0.046</td>\n",
       "      <td>0.659 Â± 0.079</td>\n",
       "      <td>0.470 Â± 0.093</td>\n",
       "      <td>0.546 Â± 0.083</td>\n",
       "      <td>0.719 Â± 0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.697 Â± 0.084</td>\n",
       "      <td>0.767 Â± 0.063</td>\n",
       "      <td>0.682 Â± 0.119</td>\n",
       "      <td>0.454 Â± 0.089</td>\n",
       "      <td>0.543 Â± 0.096</td>\n",
       "      <td>0.723 Â± 0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.699 Â± 0.078</td>\n",
       "      <td>0.765 Â± 0.058</td>\n",
       "      <td>0.776 Â± 0.127</td>\n",
       "      <td>0.387 Â± 0.094</td>\n",
       "      <td>0.506 Â± 0.090</td>\n",
       "      <td>0.731 Â± 0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.715 Â± 0.087</td>\n",
       "      <td>0.779 Â± 0.064</td>\n",
       "      <td>0.790 Â± 0.121</td>\n",
       "      <td>0.409 Â± 0.101</td>\n",
       "      <td>0.533 Â± 0.104</td>\n",
       "      <td>0.744 Â± 0.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            AUC-PR        AUC-ROC      Precision  \\\n",
       "Classifier                                                         \n",
       "Label Propagation    0.458 Â± 0.048  0.579 Â± 0.048  0.492 Â± 0.090   \n",
       "KNeighbors           0.458 Â± 0.046  0.578 Â± 0.051  0.502 Â± 0.078   \n",
       "Label Spreading      0.478 Â± 0.056  0.581 Â± 0.046  0.516 Â± 0.109   \n",
       "SVC                  0.497 Â± 0.070  0.607 Â± 0.051  0.000 Â± 0.000   \n",
       "Gaussian NB          0.514 Â± 0.052  0.668 Â± 0.038  0.507 Â± 0.043   \n",
       "Decision Tree        0.635 Â± 0.075  0.719 Â± 0.058  0.790 Â± 0.088   \n",
       "MLP Classifier       0.640 Â± 0.088  0.739 Â± 0.065  0.619 Â± 0.114   \n",
       "QDA                  0.666 Â± 0.075  0.758 Â± 0.063  0.725 Â± 0.070   \n",
       "LDA                  0.690 Â± 0.057  0.770 Â± 0.040  0.648 Â± 0.065   \n",
       "Logistic Regression  0.693 Â± 0.060  0.769 Â± 0.046  0.659 Â± 0.079   \n",
       "AdaBoost             0.697 Â± 0.084  0.767 Â± 0.063  0.682 Â± 0.119   \n",
       "Gradient Boosting    0.699 Â± 0.078  0.765 Â± 0.058  0.776 Â± 0.127   \n",
       "Random Forest        0.715 Â± 0.087  0.779 Â± 0.064  0.790 Â± 0.121   \n",
       "\n",
       "                            Recall       F1-score       Accuracy  \n",
       "Classifier                                                        \n",
       "Label Propagation    0.271 Â± 0.071  0.348 Â± 0.081  0.634 Â± 0.037  \n",
       "KNeighbors           0.255 Â± 0.063  0.336 Â± 0.070  0.638 Â± 0.028  \n",
       "Label Spreading      0.249 Â± 0.068  0.332 Â± 0.077  0.640 Â± 0.037  \n",
       "SVC                  0.000 Â± 0.000  0.000 Â± 0.000  0.636 Â± 0.002  \n",
       "Gaussian NB          0.635 Â± 0.102  0.559 Â± 0.048  0.638 Â± 0.046  \n",
       "Decision Tree        0.387 Â± 0.107  0.507 Â± 0.109  0.736 Â± 0.035  \n",
       "MLP Classifier       0.495 Â± 0.173  0.522 Â± 0.117  0.691 Â± 0.045  \n",
       "QDA                  0.399 Â± 0.063  0.512 Â± 0.058  0.725 Â± 0.027  \n",
       "LDA                  0.521 Â± 0.083  0.576 Â± 0.073  0.723 Â± 0.039  \n",
       "Logistic Regression  0.470 Â± 0.093  0.546 Â± 0.083  0.719 Â± 0.042  \n",
       "AdaBoost             0.454 Â± 0.089  0.543 Â± 0.096  0.723 Â± 0.057  \n",
       "Gradient Boosting    0.387 Â± 0.094  0.506 Â± 0.090  0.731 Â± 0.042  \n",
       "Random Forest        0.409 Â± 0.101  0.533 Â± 0.104  0.744 Â± 0.045  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af55939d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best performing model based on AUC-PR is: Random Forest\n",
      "P-values from Wilcoxon signed-rank tests comparing the best model against others:\n",
      "              Logistic Regression Ridge Classifier     LDA         QDA  \\\n",
      "Random Forest               0.322                    0.160  bold 0.027   \n",
      "\n",
      "                      SVC  KNeighbors Random Forest Gradient Boosting  \\\n",
      "Random Forest  bold 0.002  bold 0.002                           0.064   \n",
      "\n",
      "              Gaussian NB Decision Tree MLP Classifier Label Spreading  \\\n",
      "Random Forest  bold 0.002    bold 0.002     bold 0.020      bold 0.002   \n",
      "\n",
      "              Label Propagation AdaBoost  \n",
      "Random Forest        bold 0.002    0.084  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35360/2778090644.py:1: RuntimeWarning: Mean of empty slice\n",
      "  mean_auc_pr_scores = {classifier: np.nanmean(scores[classifier][\"AUC-PR\"]) for classifier in classifiers}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mean_auc_pr_scores = {classifier: np.nanmean(scores[classifier][\"AUC-PR\"]) for classifier in classifiers}\n",
    "best_model = max(mean_auc_pr_scores, key=mean_auc_pr_scores.get)\n",
    "print(f\"The best performing model based on AUC-PR is: {best_model}\")\n",
    "\n",
    "# Perform Wilcoxon signed-rank tests between the best model and all others\n",
    "p_values = pd.DataFrame(index=[best_model], columns=classifiers.keys())\n",
    "auc_pr_scores = {classifier: scores[classifier][\"AUC-PR\"] for classifier in classifiers}\n",
    "\n",
    "for classifier in classifiers.keys():\n",
    "    if classifier != best_model:\n",
    "        stat, p = wilcoxon(auc_pr_scores[best_model], auc_pr_scores[classifier])\n",
    "        p_values.loc[best_model, classifier] = p\n",
    "    else:\n",
    "        p_values.loc[best_model, classifier] = np.nan  # Self-comparison\n",
    "\n",
    "# Formatting the DataFrame to highlight p-values <= 0.05\n",
    "def highlight_p_values(val):\n",
    "    color = 'bold' if val <= 0.05 else ''\n",
    "    return f'{color} {val:.3f}' if not pd.isna(val) else ''\n",
    "\n",
    "formatted_p_values = p_values.astype(float).applymap(highlight_p_values)\n",
    "\n",
    "print(\"P-values from Wilcoxon signed-rank tests comparing the best model against others:\")\n",
    "print(formatted_p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "471fd840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <th>LDA</th>\n",
       "      <th>QDA</th>\n",
       "      <th>SVC</th>\n",
       "      <th>KNeighbors</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>Gaussian NB</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>MLP Classifier</th>\n",
       "      <th>Label Spreading</th>\n",
       "      <th>Label Propagation</th>\n",
       "      <th>AdaBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.322</td>\n",
       "      <td></td>\n",
       "      <td>0.160</td>\n",
       "      <td>bold 0.027</td>\n",
       "      <td>bold 0.002</td>\n",
       "      <td>bold 0.002</td>\n",
       "      <td></td>\n",
       "      <td>0.064</td>\n",
       "      <td>bold 0.002</td>\n",
       "      <td>bold 0.002</td>\n",
       "      <td>bold 0.020</td>\n",
       "      <td>bold 0.002</td>\n",
       "      <td>bold 0.002</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Logistic Regression Ridge Classifier     LDA         QDA  \\\n",
       "Random Forest               0.322                    0.160  bold 0.027   \n",
       "\n",
       "                      SVC  KNeighbors Random Forest Gradient Boosting  \\\n",
       "Random Forest  bold 0.002  bold 0.002                           0.064   \n",
       "\n",
       "              Gaussian NB Decision Tree MLP Classifier Label Spreading  \\\n",
       "Random Forest  bold 0.002    bold 0.002     bold 0.020      bold 0.002   \n",
       "\n",
       "              Label Propagation AdaBoost  \n",
       "Random Forest        bold 0.002    0.084  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d05d2a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC-PR</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Label Propagation</th>\n",
       "      <td>0.458 Â± 0.048</td>\n",
       "      <td>0.579 Â± 0.048</td>\n",
       "      <td>0.634 Â± 0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighbors</th>\n",
       "      <td>0.458 Â± 0.046</td>\n",
       "      <td>0.578 Â± 0.051</td>\n",
       "      <td>0.638 Â± 0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label Spreading</th>\n",
       "      <td>0.478 Â± 0.056</td>\n",
       "      <td>0.581 Â± 0.046</td>\n",
       "      <td>0.640 Â± 0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.497 Â± 0.070</td>\n",
       "      <td>0.607 Â± 0.051</td>\n",
       "      <td>0.636 Â± 0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian NB</th>\n",
       "      <td>0.514 Â± 0.052</td>\n",
       "      <td>0.668 Â± 0.038</td>\n",
       "      <td>0.638 Â± 0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.635 Â± 0.075</td>\n",
       "      <td>0.719 Â± 0.058</td>\n",
       "      <td>0.736 Â± 0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Classifier</th>\n",
       "      <td>0.640 Â± 0.088</td>\n",
       "      <td>0.739 Â± 0.065</td>\n",
       "      <td>0.691 Â± 0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.666 Â± 0.075</td>\n",
       "      <td>0.758 Â± 0.063</td>\n",
       "      <td>0.725 Â± 0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.690 Â± 0.057</td>\n",
       "      <td>0.770 Â± 0.040</td>\n",
       "      <td>0.723 Â± 0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.693 Â± 0.060</td>\n",
       "      <td>0.769 Â± 0.046</td>\n",
       "      <td>0.719 Â± 0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.697 Â± 0.084</td>\n",
       "      <td>0.767 Â± 0.063</td>\n",
       "      <td>0.723 Â± 0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.699 Â± 0.078</td>\n",
       "      <td>0.765 Â± 0.058</td>\n",
       "      <td>0.731 Â± 0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.715 Â± 0.087</td>\n",
       "      <td>0.779 Â± 0.064</td>\n",
       "      <td>0.744 Â± 0.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            AUC-PR        AUC-ROC       Accuracy\n",
       "Classifier                                                      \n",
       "Label Propagation    0.458 Â± 0.048  0.579 Â± 0.048  0.634 Â± 0.037\n",
       "KNeighbors           0.458 Â± 0.046  0.578 Â± 0.051  0.638 Â± 0.028\n",
       "Label Spreading      0.478 Â± 0.056  0.581 Â± 0.046  0.640 Â± 0.037\n",
       "SVC                  0.497 Â± 0.070  0.607 Â± 0.051  0.636 Â± 0.002\n",
       "Gaussian NB          0.514 Â± 0.052  0.668 Â± 0.038  0.638 Â± 0.046\n",
       "Decision Tree        0.635 Â± 0.075  0.719 Â± 0.058  0.736 Â± 0.035\n",
       "MLP Classifier       0.640 Â± 0.088  0.739 Â± 0.065  0.691 Â± 0.045\n",
       "QDA                  0.666 Â± 0.075  0.758 Â± 0.063  0.725 Â± 0.027\n",
       "LDA                  0.690 Â± 0.057  0.770 Â± 0.040  0.723 Â± 0.039\n",
       "Logistic Regression  0.693 Â± 0.060  0.769 Â± 0.046  0.719 Â± 0.042\n",
       "AdaBoost             0.697 Â± 0.084  0.767 Â± 0.063  0.723 Â± 0.057\n",
       "Gradient Boosting    0.699 Â± 0.078  0.765 Â± 0.058  0.731 Â± 0.042\n",
       "Random Forest        0.715 Â± 0.087  0.779 Â± 0.064  0.744 Â± 0.045"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = results_df \n",
    "temp_df = temp_df.drop([\"Precision\", \"Recall\", \"F1-score\"], axis = 1)\n",
    "temp_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textemb",
   "language": "python",
   "name": "textemb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
